{
    "categories": [
        {
            "id": "vrar",
            "title": "VR/AR Projects",
            "projects": [
                {
                    "id": "qubitvr",
                    "title": "QubitVR",
                    "link": "/projects/vrar/qubitvr",
                    "description": "QubitVR is a VR educational tool we developed as our undergraduate capstone, designed to make quantum computing concepts like Bloch spheres, single-qubit gates, superposition, and measurement accessible through interactive 3D tutorials. Guided by Dr. McMahan (VR) and Dr. Kolodrubetz (physics), our cross-functional team built a space environment in Unity where users can learn the basics of how quantum bits behave. We created grab-and-drop mechanics for NOT, Hadamard, π/2, and π/4 gates, plus a universal-rotation gate, to animate qubit state changes on the Bloch sphere. A flashlight mechanic triggers measurement collapse, followed by a dynamic display of the underlying matrix math. Three structured tutorial modules guide users through core concepts, and a sandbox mode invites open exploration. We iterated with weekly sponsor feedback, frequent playtests, and desktop prototyping via the XR Simulation Toolkit, tracking progress in Jira and Perforce. By delivering QubitVR from zero to polished prototype in under a year, I learned how to translate dense physics into user friendly interactions, design VR UIs that feel natural, and create a system geared towards education rather than just fun. Managing cross-disciplinary communication between developers, designers, and physicists taught me first-hand how complex projects get done.",
                    "headerPhoto": "/assets/photos/projects/qubitvr/qubitvr_header.png",
                    "quickFacts": [
                        {
                            "label": "Date Started",
                            "icon": "date-started.svg",
                            "value": "September 18th, 2020"
                        },
                        {
                            "label": "Date Completed",
                            "icon": "date-completed.svg",
                            "value": "April 23rd, 2021"
                        },
                        {
                            "label": "Principal Software",
                            "icon": "wrench.svg",
                            "value": "Unity"
                        },
                        {
                            "label": "Principal Hardware",
                            "icon": "hmd.svg",
                            "value": "Meta Quest 2"
                        },
                        {
                            "label": "Team",
                            "icon": "handshake.svg",
                            "value": "Javier Aguilar, Jeff Fortune, Timothy Jinks, Ahmed Mansour, Jacob Powers"
                        }
                    ],
                    "photos": [
                        {
                            "url": "/assets/photos/projects/qubitvr/1.jpg"
                        }
                    ],
                    
                    "techUsed": [
                        {
                            "label": "Unity",
                            "icon": "unity.svg",
                            "bullets": [
                                "Created a 3D spatial metaphor for quantum logic gates and qubit entanglement using animated visual objects and paths",
                                "Design interactive tutorials to relate to users the fundementals of Quantum Mechanics"
                            ]
                        }
                    ],
                    "resources": {
                        "repoUrl": "https://github.com/you/knighthacks2020"
                    }

                },
                {
                    "id": "subvrine",
                    "title": "SubVRine",
                    "link": "/projects/vrar/subvrine",
                    "description": "SubVRine began as a final class project for the Virtual Reality Engineering course led by my soon-to-be graduate advisor, Dr. Carolina Cruz-Neira. Still relatively new to the field of VR, I was primarily interested in experimenting with novel UI schemas that could best utilize the strengths of the hardware. To this end, I developed a Unity experience where you take control a submarine that dives deep to find lost treasure. The focus of my design was on how the user would interact with the submersible. I felt that the 6 degrees of freedom offered by most VR controllers had a lot of potential to create a intuitive control system, as both translation and rotation of the controllers could be used to translate and rotate the ship that the user occupied. I was, in part, inspired by previous research on the 'World-In Miniature' concept for viewport manipulation. This idea relates the virtual world to user through a small, handheld replica of the 3D scene the user is currently situated. With this representation, more of the surrounding context can be presented to the user than usual. My design expands on this, by placing a miniature of the submarine within a glass sphere in front of the user. By grabbing this 'proxy', the user can directly control the ship through a mapping of the pose of the miniature to the actual ship. Great care was taken to reduce the aggravation of nausea by applying smoothing to the movement of the ship, reducing jitters and rapid spinning. The outcome of this experiment was very promising. It felt very natural to grab the miniature and bring it to the bottom of the sphere to begin a dive, or to twist the ship to avoid obstacles. There was also a lot of room to take this concept further. For instance, more context in the form of obstacles or items could appear as proxies in the sphere as well, providing more information to the user. This proof-of-concept led directly into my follow-up work on the HoloSphere project, where I continued exploring spatial proxies and context‐rich interactions.",
                    "headerPhoto": "/assets/photos/projects/subvrine/subvrine_header.png",
                    "quickFacts": [
                        {
                            "label": "Date Started",
                            "icon": "date-started.svg",
                            "value": "September 27th, 2022"
                        },
                        {
                            "label": "Date Completed",
                            "icon": "date-completed.svg",
                            "value": "December 7th, 2022"
                        },
                        {
                            "label": "Principal Software",
                            "icon": "wrench.svg",
                            "value": "Unity"
                        },
                        {
                            "label": "Principal Hardware",
                            "icon": "hmd.svg",
                            "value": "Meta Quest 2"
                        },
                        {
                            "label": "Project Type",
                            "icon": "project-type.svg",
                            "value": "Class Project"
                        }
                    ],
                    "photos": [
                        {
                            "url": "/assets/photos/projects/subvrine/1.jpg"
                        }
                    ],
                    
                    "techUsed": [
                        {
                            "label": "Unity",
                            "icon": "unity.svg",
                            "bullets": [
                                "XR Interaction Toolkit + Oculus Integration for VR and 6-DOF interactions",
                                "Implemented a robust menu system to adjust control sphere for user comfort",
                                "Created a simple shark AI system as an obstacle to impede the player"
                            ]
                        },
                        {
                            "label": "C#",
                            "icon": "c-sharp.svg",
                            "bullets": [
                                "Custom Pose-To-Submarine logic for proxy control",
                                "Utilized smoothing techniques on transform updates to reduce VR sickness"
                            ]
                        }
                    ],
                    "resources": {
                        "repoUrl": "https://github.com/you/knighthacks2020"
                    }

                },
                {
                    "id": "solitudevr",
                    "title": "SolitudeVR",
                    "link": "/projects/vrar/solitudevr",
                    "description": "SolitudeVR started with a simple desire: could I bring tactile joy of real playing cards into Virtual Reality? I developed in Unity that marries a VR headset with AR image tracking, creating exactly this kind of soothing, interactive card-based retreat. The concept: use a set of real, Tarot-sized playing cards—each printed with a unique fiducial marker—as tangible controllers for a virtual experience. The architecture breaks down into two core modules; the AR component and the VR component. The AR component uses a webcam mounted over a table to track markers printed onto a set of custom Tarot cards. I chose the Tarot size of cards because this would allow larger makers to be used, improving detection stability. After first experimenting with a number of AR scannable marker variants such as ArUco and ARTag, I landed on AprilTags, as they were easy to generate and provided embedded error correction which improved tracking. I then designed 52 cards, each with a unique marker ID, resulting in a complete set of playing cards. Each card’s unique ID lets the system recognize not just “a card,” but exactly which one, front and back. The VR component of the project involved designing a relaxing nature environment to place the user into, and developing the logic to recognize the markers, calibrate the camera, and set up a simple card matching game. With this set up, virtual cards faces appear to be perfectly overlaid on top of the physical card, and you are able to naturally reach out and pick it up. A cool part of this project was that the system can load any image set you like, opening doors to everything from educational flashcards to bespoke art decks. I really enjoyed this project, but it was certainly a difficult one. I underestimated both how easy it would be to track the markers on the card and transmit the positional data to, and how well the tracking itself worked. A card alone on a flat surface would work well, but if other cards covered up a portion of its face (as is common in many card games), tracking would be compromised. I attempted to remedy this by adding redundant markers to the faces of the cards, but this introduced more issues due to a limit on the number trackable markers. Ultimately, I gained hands-on expertise in fiducial tracking, real-time camera calibration, and crafting user-friendly Mixed Reality UIs under real-world constraints.",
                    "headerPhoto": "/assets/photos/projects/solitudevr_header.png",
                    "quickFacts": [
                        {
                            "label": "Date Started",
                            "icon": "date-started.svg",
                            "value": "February 15th, 2023"
                        },
                        {
                            "label": "Date Completed",
                            "icon": "date-completed.svg",
                            "value": "May 2nd, 2023"
                        },
                        {
                            "label": "Principal Software",
                            "icon": "wrench.svg",
                            "value": "Unity"
                        },
                        {
                            "label": "Principal Hardware",
                            "icon": "hmd.svg",
                            "value": "Meta Quest 2"
                        },
                        {
                            "label": "Project Type",
                            "icon": "project-type.svg",
                            "value": "Class Project"
                        }
                    ],
                    "photos": [
                        {
                            "url": "/assets/photos/projects/solitudevr/1.jpg"
                        }
                    ],
                    
                    "techUsed": [
                        {
                            "label": "Unity",
                            "icon": "unity.svg",
                            "bullets": [
                                "Piped in webcam data for marker detection and calibration",
                                "Utilized noise reduction techniques such as Kalman Filtering to combat jitter",
                                "Built generic framework for implementing nearly any card game"
                            ]
                        },
                        {
                            "label": "C#",
                            "icon": "c-sharp.svg",
                            "bullets": [
                                "Decoding marker IDs from video frames"
                            ]
                        },
                        {
                            "label": "GIMP",
                            "icon": "gimp.svg",
                            "bullets": [
                                "Hand-designed 52 playing cards with unique markers to be professionally manufactured"
                            ]
                        }
                    ]
                },
                {
                    "id": "longboardvr",
                    "title": "LongboardVR",
                    "link": "/projects/coding/longboardvr",
                    "description": "LongboardVR is the final project of my first graduate graphics course, Realistic Realtime Rendering. I wanted to build something that fused my love of VR with the simple bliss of cruising on a longboard. To this end, I create a procedurally generated experience in Unity, where the goal is to skate down an infinite pathway while collecting tokens. The key points of this project is the audio-based vertex manipulation of the terrain, and its procedural generation. As my goal was to create an experience that was soothing and peaceful, I had an idea to marry the music to environment itself, almost like a music visualizer. To do this, I utilized audio processing techniques to extract the tempo of any selected song, I also extract the frequency bands (low, mid, high) of the song, and mapped that to the height of the pulses in the terrain. This synchronicity between the audio and visuals helps to create a more relaxing atmosphere. The procedural generation was done by first using a Perlin Noise function to create the base terrain. Height maps were implemented to control the color of the terrain based on the vertex vertical position. This allowed me to have water in lakes below the user, and the appearance of mountains above. Next, interpolation was done terrain so that the main path and its vicinity were made flat in a natural-looking way. This project gave me valuable insight into the balancing act between graphics (raytracing, complex shaders) and performance constraints. I originally wanted to have a more realistic lighting system, but the hardware of the Meta Quest 2 proved too limiting. Also, at the time, I was very inexperienced when it came to writing shaders. With the knowledge and experience I have now, I believe this project could be even more simultaneously exciting and relaxing.",
                    "headerPhoto": "/assets/photos/projects/longboardvr/longboardvr_header.png",
                    "photos": [
                        {
                            "url": "/assets/photos/projects/test.jpg"
                        }
                    ],
                    "quickFacts": [
                        {
                            "label": "Date Started",
                            "icon": "date-started.svg",
                            "value": "October 27th, 2023"
                        },
                        {
                            "label": "Date Completed",
                            "icon": "date-completed.svg",
                            "value": "December 6th, 2023"
                        },
                        {
                            "label": "Principal Software",
                            "icon": "wrench.svg",
                            "value": "Unity"
                        },
                        {
                            "label": "Principal Hardware",
                            "icon": "hmd.svg",
                            "value": "Meta Quest 2"
                        },
                        {
                            "label": "Project Type",
                            "icon": "project-type.svg",
                            "value": "Class Project"
                        }
                    ],
                    "techUsed": [
                        {
                            "label": "Unity",
                            "icon": "unity.svg",
                            "bullets": [
                                "Perlin Noise terrain script for dynamic and infinite generation",
                                "Height based color mapping and smooth interpolation on main path",
                                "Utilized ULAR audio access tool to extract audio band data"
                            ]
                        },
                        {
                            "label": "C#",
                            "icon": "c-sharp.svg",
                            "bullets": [
                                "Coroutine-driven token spawner and procedural generation tied to player proximity"
                            ]
                        },
                        {
                            "label": "Meta Quest 2",
                            "icon": "quest2.svg",
                            "bullets": [
                                "Coroutine-driven token spawner and procedural generation tied to player proximity",
                                "Developed a control system that mimics riding a longboard by mapping direction to leaning forwards or backwards"
                            ]
                        }
                    ]
                },
                {
                    "id": "spatialcompositions",
                    "title": "Spatial Compositions",
                    "link": "/projects/vrar/spatialcompositions",
                    "description": "Spatial Compositions is my venture into VR-based music authoring. A next-gen Digital Audio Workstation (DAW) built in Unity, it replaces traditional timelines and menus with a 3D grid of interactive blocks that represent musical elements you place and connect in space. What results is the unique ability to express oneself in a way that is both visually and aurally appealing. Under the hood, I implemented a modular block architecture: Note Blocks carry pitch and instrument data, Sample Blocks deliver percussive hits, Mod Blocks tweak sound parameters, and a single Start Block emits the pulse that propagates through the chain. Compositions emerge as users physically snap blocks together in space, then watch the signal travel, triggering sounds in sequence. Composers can explore rhythm, harmony, and dynamics with their whole body, turning abstract timelines into physical objects. Through Spatial Compositions I learned directly the power of spatial metaphors. Music is something that can be as complex as you want, and this can make the industry standard DAWs feel overwhelming. Trust me, I know. When a melody is presented here in 3D space, it can demystify musical structure for everyone.",
                    "headerPhoto": "/assets/photos/projects/longboardvr/longboardvr_header.png",
                    "photos": [
                        {
                            "url": "/assets/photos/projects/test.jpg"
                        }
                    ],
                    "quickFacts": [
                        {
                            "label": "Date Started",
                            "icon": "date-started.svg",
                            "value": "October 2024"
                        },
                        {
                            "label": "Date Completed",
                            "icon": "date-completed.svg",
                            "value": "December 2024"
                        },
                        {
                            "label": "Principal Software",
                            "icon": "wrench.svg",
                            "value": "Unity"
                        },
                        {
                            "label": "Principal Hardware",
                            "icon": "hmd.svg",
                            "value": "Meta Quest 2"
                        },
                        {
                            "label": "Project Type",
                            "icon": "project-type.svg",
                            "value": "Class Project"
                        }
                    ],
                    "techUsed": [
                        {
                            "label": "Unity",
                            "icon": "unity.svg",
                            "bullets": [
                                "XR Interaction Toolkit & Oculus XR plugin or Quest support",
                                "Custom BlockManager service to instantiate Note, Sample, Mod, and Start Blocks with color-coded frames"
                            ]
                        },
                        {
                            "label": "C#",
                            "icon": "c-sharp.svg",
                            "bullets": [
                                "Signal propagation system: event-driven chain triggering with audio playback and pitch adjustment",
                                "Runtime UI spawning on wrist-mounted canvas, with drag-and-drop block menu"
                            ]
                        },
                        {
                            "label": "Meta Quest 2",
                            "icon": "quest2.svg",
                            "bullets": [
                                "Coroutine-driven token spawner and procedural generation tied to player proximity",
                                "Developed a control system that mimics riding a longboard by mapping direction to leaning forwards or backwards"
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "id": "art",
            "title": "Art Projects",
            "projects": [
                {
                    "id": "coneman",
                    "title": "Coneman",
                    "link": "/projects/art/coneman",
                    "description": "One evening, while cruising around my university campus on my skateboard, I came across a half dozen traffic cones strewn about the top floor of a parking garage. Feeling a bit bored, I thought it might be fun challenging myself to weave through the cones on my board after lining them up. This impromptu slalom attempt did not end up going very well (I was still fairly new to skating at the time). After many a tumble, I began to get somewhat frustrated, and so I took it out on the cones, pushing and throwing them around. It felt silly, but it was then that I began to think about the story that was developing right in front of me. The story of a person trying to accomplish a goal, but was held back by their misplaced frustration, violently attacking these friendly obstacles rather than accepting their own deficiencies. It was then that Coneman was born. I began to film very soon after, as I suspected that campus officials would collect these cones sooner rather than later. After doing the first few shots on my own, I quickly realized that I would need extra hands for what I had in mind. That's when I called upon my good friend Ronan to help not only with filming, but to be the actor who would don the cones of the titular Coneman. With his help (as well as benevolent passersby), we finished filming in 3 nights. There was no script, and very little prep work. I utilized some practical effect tricks such as fishing line to move cones at a distance, and ketchup to stand in for blood. In hindsight I am very proud of the film, but I acknowledge the multitude of flaws in it, the largest of which is the visual quality. I was inexperienced with filming at night, and with no access to lights, the end result is a film with a noticeable graininess and some scenes that are simply too dark. The overhead lights on the garage gave the whole film a green tone, which was not intentional. Nonetheless, I felt that I achieved what I set out to do. The soundtrack for the film, which I composed, can be found here.",
                    "headerPhoto": "/assets/photos/projects/coneman_header.jpg",
                    "photos": [
                        {
                            "url": "/assets/photos/projects/test.jpg"
                        }
                    ],
                    "quickFacts": [
                        {
                            "label": "Filming Started",
                            "icon": "date-started.svg",
                            "value": "May 11th, 2023"
                        },
                        {
                            "label": "Filming Ended",
                            "icon": "date-completed.svg",
                            "value": "May 14th, 2023"
                        },
                        {
                            "label": "Video Editing",
                            "icon": "premiere.svg",
                            "value": "Adobe Premiere Pro"
                        },
                        {
                            "label": "Music Composition",
                            "icon": "flstudio.svg",
                            "value": "FL Studio"
                        },
                        {
                            "label": "Project Type",
                            "icon": "project-type.svg",
                            "value": "Art Project"
                        }
                    ]
                },
                {
                    "id": "mural",
                    "title": "VARLAB Wall of Fame",
                    "link": "/projects/art/mural",
                    "description": "The VARLAB Mural, otherwise known as the Wall of Fame is an Augmented Reality art installation that was designed to be a space where members of the lab have an opportunity to truly express themselves in a unique way. Installed on the second floor of Partnership II near the University of Central Florida, the mural is a large wall art piece that depicts a futuristic cityscape above a sci-fi door that bears the labaratories logo. By scanning the logo with a phone, visitors can explore an interactive directory of lab members. Each entry showcases a 3D model, a quote, and links to further explore that person’s work. The concept arose when our research group relocated into Partnership II. My professor urged us to think of ways to make this new space our own, and as we are a VR and AR based research lab, I began to think of a way to incorporate the technology into the lab itself. With my previous experience in marker-based AR and a new physical wall to work with, I envisioned a system that would let lab members actively contribute their own digital “presence” to a public installation. The mural would become both a celebration of our work and a tool for networking, storytelling, and memory. I built the system on top of AR.js, a JavaScript library that allows mobile AR directly through a web browser—no app download required. To me, this was a critical design constraint. The experience had to have as low a barrier to entry as possible so that as many people as possible would elect to spend time exploring it. However, this also meant working within the constraints of WebAR, including tracking stability, model optimization, and mobile-friendly rendering. I collaborated with Abdul Mannan Mohamed and Martin McCarthy to design the visual style of the mural itself, with the goal of making the physical and digital elements felt cohesive. With Naomi Yoon’s help, we developed a backend system for dynamically loading new content, handling model uploads, and supporting content updates through an internal admin tool. The VARLAB Mural is one of my most ambitious undertakings to date. It is a permanent installation that reflects the identity of our lab not just in its theme, but in how it allows every member to leave something behind. As the lab grows, I hope this mural continues to serve as a meaningful, creative, and technical artifact.",
                    "headerPhoto": "/assets/photos/projects/mural/mural_header.jpg",
                    "photos": [
                        {
                            "url": "/assets/photos/projects/test.jpg"
                        }
                    ],
                    "quickFacts": [
                        {
                            "label": "Date Started",
                            "icon": "date-started.svg",
                            "value": "January 2024"
                        },
                        {
                            "label": "Principal Software",
                            "icon": "wrench.svg",
                            "value": "AR.js, Three.js"
                        },
                        {
                            "label": "Team",
                            "icon": "team.svg",
                            "value": "Martin McCarthy, Abdul Mannan Mohamed, Ahmed Mansour, Naomi Yoon et al."
                        }
                    ],
                    "techUsed": [
                        {
                            "label": "AR.js",
                            "icon": "arjs.svg",
                            "bullets": [
                                "Enabled marker-based augmented reality directly in the mobile web browser",
                                "Utilized smoothing techniques to optimize tracking capability for smart phone cameras"
                            ]
                        },
                        {
                            "label": "A-Frame",
                            "icon": "aframe.svg",
                            "bullets": [
                                "Used to construct the 3D AR scene and place interactive models, quotes, and links",
                                "Achieved WebAR-friendly performance by balancing detail and optimization"
                            ]
                        },
                        {
                            "label": "Express.js",
                            "icon": "expressjs.svg",
                            "bullets": [
                                "Powered the backend for the internal admin tool that lets lab members manage their content",
                                "Handled model uploads, metadata storage, and dynamic content delivery to the AR front-end"
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "id": "research",
            "title": "Research Projects",
            "projects": [
                {
                    "id": "varlab",
                    "title": "VARLAB Research",
                    "description": "Research on the intersection of virtual reality and art.",
                    "headerPhoto": "/assets/photos/projects/varlab_header.jpg",
                    "headerPhotoWidth": 800,
                    "headerPhotoHeight": 600,
                    "photos": [
                        {
                            "url": "/assets/photos/projects/test.jpg",
                            "width": 1024,
                            "height": 768
                        }
                    ],
                    "link": "/projects/research/varlab",
                    "techUsed": [
                        {
                            "label": "Unity",
                            "icon": "unity.svg",
                            "url": "/projects/unity",
                            "bullets": [
                                "Developed interactive VR installations for art exhibitions"
                            ]
                        }
                    ]
                },
                {
                    "id": "qubitvr",
                    "title": "QubitVR",
                    "description": "An educational VR app to visualize quantum states in 3D.",
                    "headerPhoto": "/assets/photos/projects/qubitvr_header.png",
                    "headerPhotoWidth": 1911,
                    "headerPhotoHeight": 905,
                    "photos": [
                        {
                            "url": "/assets/photos/projects/test.jpg",
                            "width": 1024,
                            "height": 768
                        }
                    ],
                    "link": "/projects/coding/qubitvr",
                    "techUsed": [
                        {
                            "label": "Unity",
                            "icon": "unity.svg",
                            "url": "/projects/unity",
                            "bullets": [
                                "Visualized Bloch spheres with custom materials",
                                "Implemented hand-tracking interactions",
                                "Optimized shader performance for VR"
                            ]
                        },
                        {
                            "label": "C#",
                            "icon": "csharp.svg",
                            "url": "/projects/csharp",
                            "bullets": [
                                "Wrote clean, modular code for quantum state transitions",
                                "Used async patterns to load resources on demand"
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "id": "toys",
            "title": "Toys",
            "projects": [
                {
                    "id": "patternfactory",
                    "title": "Pattern Factory",
                    "description": "A generative art toy that creates unique geometric patterns.",
                    "headerPhoto": "/assets/photos/projects/toys_header.jpg",
                    "headerPhotoWidth": 800,
                    "headerPhotoHeight": 600,
                    "photos": [
                        {
                            "url": "/assets/photos/projects/test.jpg",
                            "width": 1024,
                            "height": 768
                        }
                    ],
                    "link": "/projects/toys/patternfactory",
                    "techUsed": [
                        {
                            "label": "three.js",
                            "icon": "threejs.svg",
                            "url": "/projects/threejs",
                            "bullets": [
                                "Created generative art pieces using code"
                            ]
                        }
                    ]
                },
                {
                    "id": "concentriccircle",
                    "title": "Concentric Circles",
                    "description": "An audio-visualizer that paints concentric rings to music.",
                    "headerPhoto": "/assets/photos/projects/concentriccircle_header.png",
                    "headerPhotoWidth": 799,
                    "headerPhotoHeight": 629,
                    "photos": [
                        {
                            "url": "/assets/photos/projects/test.jpg",
                            "width": 1024,
                            "height": 768
                        }
                    ],
                    "link": "/projects/coding/concentriccircle",
                    "techUsed": [
                        {
                            "label": "p5.js",
                            "icon": "p5js.svg",
                            "url": "/projects/p5js",
                            "bullets": [
                                "Drew dynamic concentric rings synced to audio FFT",
                                "Experimented with color harmonies based on frequency bands"
                            ]
                        }
                    ]
                },
                {
                    "id": "battletetris",
                    "title": "BattleTetris",
                    "description": "Multiplayer competitive Tetris clone with power-ups.",
                    "headerPhoto": "/assets/photos/projects/battletetris_header.png",
                    "headerPhotoWidth": 799,
                    "headerPhotoHeight": 629,
                    "photos": [
                        {
                            "url": "/assets/photos/projects/test.jpg",
                            "width": 1024,
                            "height": 768
                        }
                    ],
                    "link": "/projects/coding/battletetris",
                    "techUsed": [
                        {
                            "label": "React",
                            "icon": "reactjs.svg",
                            "url": "/projects/reactjs",
                            "bullets": [
                                "Built game UI with hooks and context",
                                "Synced state across clients via WebSockets"
                            ]
                        },
                        {
                            "label": "Node.js",
                            "icon": "nodejs.svg",
                            "url": "/projects/nodejs",
                            "bullets": [
                                "Authored real-time server for matchmaking and power-ups"
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "id": "archive",
            "title": "Archived Projects",
            "projects": [
                {
                    "id": "escapevroom",
                    "title": "EscapeVRoom",
                    "description": "My Senior Design team wanted to improve our skills developing for Virtual Reality, so we decided to participate in Knight Hacks, a hackathon hosted by the University of Central Florida. We had some time before work began on our final project, so we saw the hackathon as the perfect opportunity to challenge ourselves in a fast-paced, collaborative environment. With a weekend to build something from scratch, we focused on designing an immersive escape room experience in Unity.\n\nEscapeVRoom is a single-level escape room filled with interactive items, environmental puzzles, and game scripts to guide the player toward unlocking the final door. We divided responsibilities among the team based on interest and experience: I focused on scripting major mechanics like the bookshelf and fireplace puzzle, while also integrating everyone’s code into a unified project. Javier designed the environment and puzzle logic, and Jacob set up item interactions and built core functionality like the silver key and chest. Working closely as a team, we were able to teach each other new tools and quickly adapt to the challenges of Unity development.\n\nThis project helped me gain hands-on experience using the full range of Unity’s development tools—from animation and scripting to environment design and interaction systems. It was also a great opportunity to deepen my C# skills and practice building a functional VR experience under a time constraint.",
                    "headerPhoto": "/assets/photos/projects/escapevroom/header.png",
                    "keyTakeaways": [
                        "Improved real-time collaboration skills",
                        "Learned how to handle API rate limits effectively",
                        "Gained experience with WebSockets for real-time updates"
                    ],
                    "photos": [
                        {
                            "url": "/assets/photos/projects/escapevroom/1.png"
                        }
                    ],
                    "link": "/projects/archive/escapevroom",
                    "dateCompleted": "October 7th, 2020",
                    "softwareUsed": "Unity",
                    "hardware": "Meta Quest 2",
                    "teamMembers": [
                        "Javier Aguilar",
                        "Jeff Fortune",
                        "Timothy Jinks",
                        "Jacob Powers"
                    ],
                    "sponsors": [
                        "Dr. Ryan McMahan",
                        "\nDr. Michael Kolodrubetz"
                    ],
                    "techUsed": [
                        {
                            "label": "Unity",
                            "icon": "unity.svg",
                            "url": "/projects/unity",
                            "bullets": [
                                "Built core 3D environment and physics interactions",
                                "Utilized Unity's XR Toolkit for VR interactions"
                            ]
                        }
                    ],
                    "resources": {
                        "repoUrl": "https://github.com/you/knighthacks2020",
                        "downloadUrl": "/assets/zips/knighthacks2020.zip",
                        "liveUrl": "https://yourgamehost.com/knighthacks2020"
                    }
                }
            ]
        },
        {
            "id": "xplor",
            "title": "Xplor",
            "projects": [
                {
                    "id": "xplor",
                    "title": "Xplor",
                    "description": "TestDescription",
                    "headerPhoto": "/assets/photos/projects/xplor/xplor_header.jpg",
                    "keyTakeaways": [
                        "Improved real-time collaboration skills",
                        "Learned how to handle API rate limits effectively",
                        "Gained experience with WebSockets for real-time updates"
                    ],
                    "photos": [
                        {
                            "url": "/assets/photos/projects/xplor/1.jpg"
                        }
                    ],
                    "link": "/projects/xplor/xplor",
                    "dateCompleted": "October 7th, 2020",
                    "softwareUsed": "Unity",
                    "hardware": "Meta Quest 2",
                    "teamMembers": [
                        "Javier Aguilar",
                        "Jeff Fortune",
                        "Timothy Jinks",
                        "Jacob Powers"
                    ],
                    "sponsors": [
                        "Dr. Ryan McMahan",
                        "\nDr. Michael Kolodrubetz"
                    ],
                    "techUsed": [
                        {
                            "label": "Unity",
                            "icon": "unity.svg",
                            "url": "/projects/unity",
                            "bullets": [
                                "Built core 3D environment and physics interactions",
                                "Utilized Unity's XR Toolkit for VR interactions"
                            ]
                        }
                    ],
                    "repoUrl": "https://github.com/you/knighthacks2020",
                    "downloadUrl": "/assets/zips/knighthacks2020.zip",
                    "liveUrl": "https://yourgamehost.com/knighthacks2020"
                }
            ]
        }
    ]
}